[{"content":"连接的建立 三次握手 正常情况下，建立连接需要经过三次握手 连接的终止 正常终止（四次挥手） 正常情况下，断开连接需要经过四次挥手 异常终止（RST报文） 主动终止方发送RST报文立刻终止连接\n处于TIME_WAIT状态的连接过多怎么办？ 如何查看连接状态？ 1 2 3 4 5 ❯ netstat -ant|awk \u0026#39;/^tcp/ {++S[$NF]} END {for(a in S) print (a,S[a])}\u0026#39; LISTEN 32 CLOSE_WAIT 7 TIME_WAIT 3 ESTABLISHED 119 什么情况下会产生大量的TIME_WAIT连接？ 我们知道TIME_WAIT是主动正常断开连接的一方所处的最后一个状态，这个状态会经历2MSL时长（2*30s） 在Nginx反向代理中，在高并发短连接的场景下，可能导致大量的TIME_WAIT连接\nTIME_WAIT 危害 对于客户端：处于TIME_WAIT状态的连接占用的端口无法被再次使用，可能会导致端口耗尽，无法建立新的连接 对于服务端：大量的连接不被释放会消耗内存 控制最大TIME_WAIT连接数 Linux提供了tcp_max_tw_buckets参数，当TIME_WAIT连接数等于此参数值时，新的连接关闭时不会再经历TIME_WAIT状态，而是直接关闭。\n重用连接 Linux提供了tcp_tw_reuse 参数允许复用处于TIME_WAIT状态的连接\n","date":"2023-09-19T00:00:00Z","permalink":"https://cloudjjcc.github.io/p/tcp%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/","title":"tcp必知必会"},{"content":"SDS SDS是Redis中存储string的底层数据结构，定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */ struct __attribute__ ((__packed__)) sdshdr5 { unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr8 { uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr16 { uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr32 { uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; struct __attribute__ ((__packed__)) sdshdr64 { uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[]; }; 对比c语言字符串，SDS实现为动态字符数组，可以高效的进行strlen,append等操作，并且是二进制安全的 Redis用不同类型的结构体（主要区别在于len和alloc字段）存储不同大小的string，使用attribute ((packed))来实现紧凑的内存布局，从而节省内存消耗。 skiplist skiplist(跳表)是zset的底层数据结构之一， 跳表实现为多层链表结构，其顶层链表节点比底层少，可以起到索引的作用: 其结构定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 跳表节点 typedef struct zskiplistNode { sds ele;//元素值 double score;//分值 struct zskiplistNode *backward;//前驱节点 struct zskiplistLevel { struct zskiplistNode *forward;//后继节点 unsigned long span;//与后继节点间的跨度 } level[]; } zskiplistNode; // 跳表 typedef struct zskiplist { struct zskiplistNode *header, *tail; unsigned long length; int level;//层级 } zskiplist; // 跳表实现的zset 结构 typedef struct zset { dict *dict; zskiplist *zsl; } zset; 查找 redis 中的跳表支持两种类型的查找：\nbyscore 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /* Find the first node that is contained in the specified range. * Returns NULL when no element is contained in the range. */ zskiplistNode *zslFirstInRange(zskiplist *zsl, zrangespec *range) { zskiplistNode *x; int i; /* If everything is out of range, return early. */ if (!zslIsInRange(zsl,range)) return NULL; x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { /* Go forward while *OUT* of range. */ while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; !zslValueGteMin(x-\u0026gt;level[i].forward-\u0026gt;score,range)) x = x-\u0026gt;level[i].forward; } /* This is an inner range, so the next node cannot be NULL. */ x = x-\u0026gt;level[0].forward; serverAssert(x != NULL); /* Check if score \u0026lt;= max. */ if (!zslValueLteMax(x-\u0026gt;score,range)) return NULL; return x; } byrank 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* Finds an element by its rank. The rank argument needs to be 1-based. */ zskiplistNode* zslGetElementByRank(zskiplist *zsl, unsigned long rank) { zskiplistNode *x; unsigned long traversed = 0;//当前节点的编号 int i; x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; (traversed + x-\u0026gt;level[i].span) \u0026lt;= rank) { traversed += x-\u0026gt;level[i].span; x = x-\u0026gt;level[i].forward; } if (traversed == rank) { return x; } } return NULL; } 这两种查找过程是类似的:\n从顶层开始查找 找到该层最后一个小于目标值的节点 进入下一层查找或退出 判断退出时的节点的下一个节点值是否等于目标值 由于底层是双链表结构，所以可以很好的支持范围查找，只需要根据找到的起始值进行前（后）向遍历即可。\n插入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) { zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; serverAssert(!isnan(score)); x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { /* store rank that is crossed to reach the insert position */ rank[i] = i == (zsl-\u0026gt;level-1) ? 0 : rank[i+1]; while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; (x-\u0026gt;level[i].forward-\u0026gt;score \u0026lt; score || (x-\u0026gt;level[i].forward-\u0026gt;score == score \u0026amp;\u0026amp; sdscmp(x-\u0026gt;level[i].forward-\u0026gt;ele,ele) \u0026lt; 0))) { rank[i] += x-\u0026gt;level[i].span; x = x-\u0026gt;level[i].forward; } update[i] = x; } // 获得一个随机层数 level = zslRandomLevel(); if (level \u0026gt; zsl-\u0026gt;level) { for (i = zsl-\u0026gt;level; i \u0026lt; level; i++) { rank[i] = 0; update[i] = zsl-\u0026gt;header; update[i]-\u0026gt;level[i].span = zsl-\u0026gt;length; } zsl-\u0026gt;level = level;//更新跳表层数 } // 创建新节点 x = zslCreateNode(level,score,ele); // 更新新节点的每一层指针关系 for (i = 0; i \u0026lt; level; i++) { x-\u0026gt;level[i].forward = update[i]-\u0026gt;level[i].forward; update[i]-\u0026gt;level[i].forward = x; /* update span covered by update[i] as x is inserted here */ x-\u0026gt;level[i].span = update[i]-\u0026gt;level[i].span - (rank[0] - rank[i]); update[i]-\u0026gt;level[i].span = (rank[0] - rank[i]) + 1; } /* increment span for untouched levels */ for (i = level; i \u0026lt; zsl-\u0026gt;level; i++) { update[i]-\u0026gt;level[i].span++; } // 更新新节点的backward指针 x-\u0026gt;backward = (update[0] == zsl-\u0026gt;header) ? NULL : update[0]; if (x-\u0026gt;level[0].forward) x-\u0026gt;level[0].forward-\u0026gt;backward = x; else zsl-\u0026gt;tail = x; zsl-\u0026gt;length++;//更新跳表长度 return x; } 插入的过程：\n找到每层的插入位置（待插入节点的前驱节点）记录到update数组中 初始化待插入的节点 将新节点插入到每一层 这个过程中有几个细节的点：\n初始化新节点时需要生成一个随机的层数 1 2 3 4 5 6 int zslRandomLevel(void) { int level = 1; while ((random()\u0026amp;0xFFFF) \u0026lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level\u0026lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL; }//其中 ZSKIPLIST_P=0.25 ZSKIPLIST_MAXLEVEL=32 span值的更新,span值用来支持编号查询 backward指针的更新，仅在底层 删除 删除的过程类似于新增的过程，需要先找到update数组和待删除的节点x, 具体删除节点的代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) { int i; for (i = 0; i \u0026lt; zsl-\u0026gt;level; i++) { if (update[i]-\u0026gt;level[i].forward == x) { update[i]-\u0026gt;level[i].span += x-\u0026gt;level[i].span - 1;//更新span update[i]-\u0026gt;level[i].forward = x-\u0026gt;level[i].forward;//更新forward指针 } else { update[i]-\u0026gt;level[i].span -= 1;//更新span } } if (x-\u0026gt;level[0].forward) { x-\u0026gt;level[0].forward-\u0026gt;backward = x-\u0026gt;backward;//更新backward指针 } else { zsl-\u0026gt;tail = x-\u0026gt;backward; } // 更新跳表层数 while(zsl-\u0026gt;level \u0026gt; 1 \u0026amp;\u0026amp; zsl-\u0026gt;header-\u0026gt;level[zsl-\u0026gt;level-1].forward == NULL) zsl-\u0026gt;level--; zsl-\u0026gt;length--;//更新跳表长度 } ","date":"2019-05-20T00:00:00Z","permalink":"https://cloudjjcc.github.io/p/redis-%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"redis 底层数据结构"},{"content":"进程在哪些情况下会退出？ 正常退出，程序crash，收到kill信号（如CTRL+C会向进程发送SIGINT信号，或者用kill命令发送信号）\nkill PID 与 kill -9 PID 的区别 kill PID 发送的是SIGTERM信号，可以被程序捕获 kill -9 PID 发送的是SIGKILL信号，不能被捕获，进程会被强制退出 优雅退出原理 通过监听可被捕获的退出信号，如：SIGTERM，SIGINT等，在程序退出前完成收尾工作。\ngo语言中信号处理 go语言中可通过以下代码监听退出信号：\n1 2 3 4 sigCh := make(chan os.Signal, 1) signal.Notify(sigCh, syscall.SIGTERM, syscall.SIGINT) \u0026lt;-sigCh // 执行程序收尾工作。。。 http server 优雅退出 可以通过Shutdown方法进行优雅退出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // Shutdown gracefully shuts down the server without interrupting any // active connections. Shutdown works by first closing all open // listeners, then closing all idle connections, and then waiting // indefinitely for connections to return to idle and then shut down. // If the provided context expires before the shutdown is complete, // Shutdown returns the context\u0026#39;s error, otherwise it returns any // error returned from closing the Server\u0026#39;s underlying Listener(s). // // When Shutdown is called, Serve, ListenAndServe, and // ListenAndServeTLS immediately return ErrServerClosed. Make sure the // program doesn\u0026#39;t exit and waits instead for Shutdown to return. // // Shutdown does not attempt to close nor wait for hijacked // connections such as WebSockets. The caller of Shutdown should // separately notify such long-lived connections of shutdown and wait // for them to close, if desired. See RegisterOnShutdown for a way to // register shutdown notification functions. // // Once Shutdown has been called on a server, it may not be reused; // future calls to methods such as Serve will return ErrServerClosed. func (srv *Server) Shutdown(ctx context.Context) error {...} gRPC server 优雅退出 相应的gRPC server 也提供了优雅关闭的方法：\n1 2 3 4 // GracefulStop stops the gRPC server gracefully. It stops the server from // accepting new connections and RPCs and blocks until all the pending RPCs are // finished. func (s *Server) GracefulStop() {...} k8s pod 优雅退出 我们先来看Pod的退出流程：\nPod 被删除，状态置为 Terminating。 kube-proxy 更新转发规则，将 Pod 从 service 的 endpoint 列表中摘除掉，新的流量不再转发到该 Pod。 如果 Pod 配置了 preStop Hook ，将会执行。 kubelet 对 Pod 中各个 container 发送 SIGTERM 信号以通知容器进程开始优雅停止。 等待容器进程完全停止，如果在 terminationGracePeriodSeconds 内 (默认 30s) 还未完全停止，就发送 SIGKILL 信号强制杀死进程。 所有容器进程终止，清理 Pod 资源。 要想实现Pod的优雅退出，需要我们的业务程序监听SIGTERM信号，并保证在terminationGracePeriodSeconds内完成退出，否则进程会被强制退出\n","date":"2019-05-08T00:00:00Z","permalink":"https://cloudjjcc.github.io/p/go%E7%A8%8B%E5%BA%8F%E4%BC%98%E9%9B%85%E9%80%80%E5%87%BA/","title":"go程序优雅退出"},{"content":"简介 net/http 包是 go 语言自带的包，实现了高性能的 http 服务器及 http 客户端，利用这个自带的包能够轻松的进行 web 开发。很多第三方的框架只不过是对此进行了封装，例如 web 框架 gin 主要是强化了路由部分。下面我们就来通过源码对此包进行分析。\n创建 HTTP 服务 1 2 3 4 5 6 7 8 9 10 11 12 13 // 创建httpserver func main() { // 注册路由 /demo1 http.Handle(\u0026#34;/demo1\u0026#34;, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026#34;demo1\u0026#34;)) })) // 注册路由 /demo2 http.HandleFunc(\u0026#34;/demo2\u0026#34;, func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(\u0026#34;demo2\u0026#34;)) }) // 开启服务，监听 7777端口 http.ListenAndServe(\u0026#34;:7777\u0026#34;, nil) } 上面的代码完成了一个简单的 http 服务，我们使用了net/http 中的三个方法，http.Handle 、http.HandleFunc、 http.ListenAndServe\n路由管理 ServeMux 首先，我们来看个接口Handler\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // A Handler responds to an HTTP request. // // ServeHTTP should write reply headers and data to the ResponseWriter // and then return. Returning signals that the request is finished; it // is not valid to use the ResponseWriter or read from the // Request.Body after or concurrently with the completion of the // ServeHTTP call. // // Depending on the HTTP client software, HTTP protocol version, and // any intermediaries between the client and the Go server, it may not // be possible to read from the Request.Body after writing to the // ResponseWriter. Cautious handlers should read the Request.Body // first, and then reply. // // Except for reading the body, handlers should not modify the // provided Request. // // If ServeHTTP panics, the server (the caller of ServeHTTP) assumes // that the effect of the panic was isolated to the active request. // It recovers the panic, logs a stack trace to the server error log, // and either closes the network connection or sends an HTTP/2 // RST_STREAM, depending on the HTTP protocol. To abort a handler so // the client sees an interrupted response but the server doesn\u0026#39;t log // an error, panic with the value ErrAbortHandler. type Handler interface { ServeHTTP(ResponseWriter, *Request) } 它只有一个 ServeHTTP 的方法，负责处理 http 的请求和响应。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // net/http server.go // DefaultServeMux is the default ServeMux used by Serve. var DefaultServeMux = \u0026amp;defaultServeMux var defaultServeMux ServeMux // Handle registers the handler for the given pattern // in the DefaultServeMux. // The documentation for ServeMux explains how patterns are matched. func Handle(pattern string, handler Handler) { DefaultServeMux.Handle(pattern, handler) } // HandleFunc registers the handler function for the given pattern // in the DefaultServeMux. // The documentation for ServeMux explains how patterns are matched. func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } 可以看到http.Handle 和http.HandleFunc 其实都是调用了DefaultServeMux的方法,而DefaultServeMux是ServeMux类型的变量,是net/http包的默认路由管理组件。\n1 2 3 4 5 6 7 8 // net/http server.go type ServeMux struct { mu sync.RWMutex m map[string]muxEntry es []muxEntry // slice of entries sorted from longest to shortest. hosts bool // whether any patterns contain hostnames } ServeMux是一个结构体，负责路由管理,即：注册和查找路由，下面我们来看它的具体方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 // Handle registers the handler for the given pattern. // If a handler already exists for pattern, Handle panics. func (mux *ServeMux) Handle(pattern string, handler Handler) { mux.mu.Lock() defer mux.mu.Unlock() if pattern == \u0026#34;\u0026#34; { panic(\u0026#34;http: invalid pattern\u0026#34;) } if handler == nil { panic(\u0026#34;http: nil handler\u0026#34;) } if _, exist := mux.m[pattern]; exist { panic(\u0026#34;http: multiple registrations for \u0026#34; + pattern) } if mux.m == nil { mux.m = make(map[string]muxEntry) } e := muxEntry{h: handler, pattern: pattern} mux.m[pattern] = e if pattern[len(pattern)-1] == \u0026#39;/\u0026#39; { mux.es = appendSorted(mux.es, e)//按路由的长度排序后添加到es中 } if pattern[0] != \u0026#39;/\u0026#39; { mux.hosts = true } } // HandleFunc registers the handler function for the given pattern. func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(\u0026#34;http: nil handler\u0026#34;) } mux.Handle(pattern, HandlerFunc(handler)) } 上面的两个函数负责注册路由，其中HandleFunc 将函数类型的参数handler转换成了HandlerFunc类型，再调用Handle函数。注册路由的过程比较简单，路由信息封装到muxEntry结构体中，被保存到了名为m的 map 中，又添加到名为es的切片中。\n1 2 3 4 5 6 7 8 9 10 // The HandlerFunc type is an adapter to allow the use of // ordinary functions as HTTP handlers. If f is a function // with the appropriate signature, HandlerFunc(f) is a // Handler that calls f. type HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r). func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) { f(w, r) } 可见，HandlerFunc是一个实现了Handler接口的函数类型。\n下面我们继续看 ServeMux 查找路由的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 // ServeHTTP dispatches the request to the handler whose // pattern most closely matches the request URL. func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURI == \u0026#34;*\u0026#34; { if r.ProtoAtLeast(1, 1) { w.Header().Set(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) } w.WriteHeader(StatusBadRequest) return } h, _ := mux.Handler(r) h.ServeHTTP(w, r) } // Handler returns the handler to use for the given request, // consulting r.Method, r.Host, and r.URL.Path. It always returns // a non-nil handler. If the path is not in its canonical form, the // handler will be an internally-generated handler that redirects // to the canonical path. If the host contains a port, it is ignored // when matching handlers. // // The path and host are used unchanged for CONNECT requests. // // Handler also returns the registered pattern that matches the // request or, in the case of internally-generated redirects, // the pattern that will match after following the redirect. // // If there is no registered handler that applies to the request, // Handler returns a ``page not found\u0026#39;\u0026#39; handler and an empty pattern. func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { // CONNECT requests are not canonicalized. if r.Method == \u0026#34;CONNECT\u0026#34; { // If r.URL.Path is /tree and its handler is not registered, // the /tree -\u0026gt; /tree/ redirect applies to CONNECT requests // but the path canonicalization does not. if u, ok := mux.redirectToPathSlash(r.URL.Host, r.URL.Path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } return mux.handler(r.Host, r.URL.Path) } // All other requests have any port stripped and path cleaned // before passing to mux.handler. host := stripHostPort(r.Host) path := cleanPath(r.URL.Path) // If the given path is /tree and its handler is not registered, // redirect for /tree/. if u, ok := mux.redirectToPathSlash(host, path, r.URL); ok { return RedirectHandler(u.String(), StatusMovedPermanently), u.Path } if path != r.URL.Path { _, pattern = mux.handler(host, path) url := *r.URL url.Path = path return RedirectHandler(url.String(), StatusMovedPermanently), pattern } return mux.handler(host, r.URL.Path) } // handler is the main implementation of Handler. // The path is known to be in canonical form, except for CONNECT methods. func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { mux.mu.RLock() defer mux.mu.RUnlock() // Host-specific pattern takes precedence over generic ones if mux.hosts { h, pattern = mux.match(host + path) } if h == nil { h, pattern = mux.match(path) } if h == nil { h, pattern = NotFoundHandler(), \u0026#34;\u0026#34; } return } 上面代码展示了ServeMux的三个方法ServeHTTP、Handler、handler,可见ServeMux实现了Handler接口，\nServeHTTP 方法是路由服务的入口点，层层调用Handler、handler方法，在handler方法中最终调用match方法进行路由匹配得到路由对应的Handler然后执行Handler的ServeHTTP方法,可见Handler既可以是一个确定的路由，也可以是一个路由管理器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // Find a handler on a handler map given a path string. // Most-specific (longest) pattern wins. func (mux *ServeMux) match(path string) (h Handler, pattern string) { // Check for exact match first. v, ok := mux.m[path] if ok { return v.h, v.pattern } // Check for longest valid match. mux.es contains all patterns // that end in / sorted from longest to shortest. for _, e := range mux.es { if strings.HasPrefix(path, e.pattern) { return e.h, e.pattern } } return nil, \u0026#34;\u0026#34; } 路由查找分为两步：\nmap 查找 分片查找 map 查找是完全匹配，若查找不到，则到分片中根据前缀匹配，因为分片是按长到短排序的，所以找到的是匹配前缀最长的Handler\n核心服务 Server 下面我们来看http.ListenAndServe函数\n1 2 3 4 5 6 7 8 9 10 11 // ListenAndServe listens on the TCP network address addr and then calls // Serve with handler to handle requests on incoming connections. // Accepted connections are configured to enable TCP keep-alives. // // The handler is typically nil, in which case the DefaultServeMux is used. // // ListenAndServe always returns a non-nil error. func ListenAndServe(addr string, handler Handler) error { server := \u0026amp;Server{Addr: addr, Handler: handler} return server.ListenAndServe() } 该函数创建了Server结构体变量，然后调用了server的ListenAndServe方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 // A Server defines parameters for running an HTTP server. // The zero value for Server is a valid configuration. type Server struct { Addr string // TCP address to listen on, \u0026#34;:http\u0026#34; if empty Handler Handler // handler to invoke, http.DefaultServeMux if nil // TLSConfig optionally provides a TLS configuration for use // by ServeTLS and ListenAndServeTLS. Note that this value is // cloned by ServeTLS and ListenAndServeTLS, so it\u0026#39;s not // possible to modify the configuration with methods like // tls.Config.SetSessionTicketKeys. To use // SetSessionTicketKeys, use Server.Serve with a TLS Listener // instead. TLSConfig *tls.Config // ReadTimeout is the maximum duration for reading the entire // request, including the body. // // Because ReadTimeout does not let Handlers make per-request // decisions on each request body\u0026#39;s acceptable deadline or // upload rate, most users will prefer to use // ReadHeaderTimeout. It is valid to use them both. ReadTimeout time.Duration // ReadHeaderTimeout is the amount of time allowed to read // request headers. The connection\u0026#39;s read deadline is reset // after reading the headers and the Handler can decide what // is considered too slow for the body. If ReadHeaderTimeout // is zero, the value of ReadTimeout is used. If both are // zero, there is no timeout. ReadHeaderTimeout time.Duration // WriteTimeout is the maximum duration before timing out // writes of the response. It is reset whenever a new // request\u0026#39;s header is read. Like ReadTimeout, it does not // let Handlers make decisions on a per-request basis. WriteTimeout time.Duration // IdleTimeout is the maximum amount of time to wait for the // next request when keep-alives are enabled. If IdleTimeout // is zero, the value of ReadTimeout is used. If both are // zero, there is no timeout. IdleTimeout time.Duration // MaxHeaderBytes controls the maximum number of bytes the // server will read parsing the request header\u0026#39;s keys and // values, including the request line. It does not limit the // size of the request body. // If zero, DefaultMaxHeaderBytes is used. MaxHeaderBytes int // TLSNextProto optionally specifies a function to take over // ownership of the provided TLS connection when an NPN/ALPN // protocol upgrade has occurred. The map key is the protocol // name negotiated. The Handler argument should be used to // handle HTTP requests and will initialize the Request\u0026#39;s TLS // and RemoteAddr if not already set. The connection is // automatically closed when the function returns. // If TLSNextProto is not nil, HTTP/2 support is not enabled // automatically. TLSNextProto map[string]func(*Server, *tls.Conn, Handler) // ConnState specifies an optional callback function that is // called when a client connection changes state. See the // ConnState type and associated constants for details. ConnState func(net.Conn, ConnState) // ErrorLog specifies an optional logger for errors accepting // connections, unexpected behavior from handlers, and // underlying FileSystem errors. // If nil, logging is done via the log package\u0026#39;s standard logger. ErrorLog *log.Logger // BaseContext optionally specifies a function that returns // the base context for incoming requests on this server. // The provided Listener is the specific Listener that\u0026#39;s // about to start accepting requests. // If BaseContext is nil, the default is context.Background(). // If non-nil, it must return a non-nil context. BaseContext func(net.Listener) context.Context // ConnContext optionally specifies a function that modifies // the context used for a new connection c. The provided ctx // is derived from the base context and has a ServerContextKey // value. ConnContext func(ctx context.Context, c net.Conn) context.Context disableKeepAlives int32 // accessed atomically. inShutdown int32 // accessed atomically (non-zero means we\u0026#39;re in Shutdown) nextProtoOnce sync.Once // guards setupHTTP2_* init nextProtoErr error // result of http2.ConfigureServer if used mu sync.Mutex listeners map[*net.Listener]struct{} activeConn map[*conn]struct{} doneChan chan struct{} onShutdown []func() } // ListenAndServe listens on the TCP network address srv.Addr and then // calls Serve to handle requests on incoming connections. // Accepted connections are configured to enable TCP keep-alives. // // If srv.Addr is blank, \u0026#34;:http\u0026#34; is used. // // ListenAndServe always returns a non-nil error. After Shutdown or Close, // the returned error is ErrServerClosed. func (srv *Server) ListenAndServe() error { if srv.shuttingDown() { return ErrServerClosed } addr := srv.Addr if addr == \u0026#34;\u0026#34; { addr = \u0026#34;:http\u0026#34; } ln, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) if err != nil { return err } return srv.Serve(ln) } 可以看到ListenAndServe方法监听了tcp套接字，并将listener作为Serve方法的参数进行调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 // Serve accepts incoming connections on the Listener l, creating a // new service goroutine for each. The service goroutines read requests and // then call srv.Handler to reply to them. // // HTTP/2 support is only enabled if the Listener returns *tls.Conn // connections and they were configured with \u0026#34;h2\u0026#34; in the TLS // Config.NextProtos. // // Serve always returns a non-nil error and closes l. // After Shutdown or Close, the returned error is ErrServerClosed. func (srv *Server) Serve(l net.Listener) error { if fn := testHookServerServe; fn != nil { fn(srv, l) // call hook with unwrapped listener } origListener := l l = \u0026amp;onceCloseListener{Listener: l} defer l.Close() if err := srv.setupHTTP2_Serve(); err != nil { return err } if !srv.trackListener(\u0026amp;l, true) { return ErrServerClosed } defer srv.trackListener(\u0026amp;l, false) var tempDelay time.Duration // how long to sleep on accept failure baseCtx := context.Background() if srv.BaseContext != nil { baseCtx = srv.BaseContext(origListener) if baseCtx == nil { panic(\u0026#34;BaseContext returned a nil context\u0026#34;) } } ctx := context.WithValue(baseCtx, ServerContextKey, srv) for { rw, e := l.Accept() if e != nil { select { case \u0026lt;-srv.getDoneChan(): return ErrServerClosed default: } if ne, ok := e.(net.Error); ok \u0026amp;\u0026amp; ne.Temporary() { if tempDelay == 0 { tempDelay = 5 * time.Millisecond } else { tempDelay *= 2 } if max := 1 * time.Second; tempDelay \u0026gt; max { tempDelay = max } srv.logf(\u0026#34;http: Accept error: %v; retrying in %v\u0026#34;, e, tempDelay) time.Sleep(tempDelay) continue } return e } if cc := srv.ConnContext; cc != nil { ctx = cc(ctx, rw) if ctx == nil { panic(\u0026#34;ConnContext returned nil\u0026#34;) } } tempDelay = 0 c := srv.newConn(rw) c.setState(c.rwc, StateNew) // before Serve can return go c.serve(ctx) } } 上面的代码完成了一个典型的 TCP 服务器，在 for 循环中处理连接，每获得一个新的连接就开一个新的协程去处理。这里的连接进一步封装了net.Conn\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 // A conn represents the server side of an HTTP connection. type conn struct { // server is the server on which the connection arrived. // Immutable; never nil. server *Server // cancelCtx cancels the connection-level context. cancelCtx context.CancelFunc // rwc is the underlying network connection. // This is never wrapped by other types and is the value given out // to CloseNotifier callers. It is usually of type *net.TCPConn or // *tls.Conn. rwc net.Conn // remoteAddr is rwc.RemoteAddr().String(). It is not populated synchronously // inside the Listener\u0026#39;s Accept goroutine, as some implementations block. // It is populated immediately inside the (*conn).serve goroutine. // This is the value of a Handler\u0026#39;s (*Request).RemoteAddr. remoteAddr string // tlsState is the TLS connection state when using TLS. // nil means not TLS. tlsState *tls.ConnectionState // werr is set to the first write error to rwc. // It is set via checkConnErrorWriter{w}, where bufw writes. werr error // r is bufr\u0026#39;s read source. It\u0026#39;s a wrapper around rwc that provides // io.LimitedReader-style limiting (while reading request headers) // and functionality to support CloseNotifier. See *connReader docs. r *connReader // bufr reads from r. bufr *bufio.Reader // bufw writes to checkConnErrorWriter{c}, which populates werr on error. bufw *bufio.Writer // lastMethod is the method of the most recent request // on this connection, if any. lastMethod string curReq atomic.Value // of *response (which has a Request in it) curState struct{ atomic uint64 } // packed (unixtime\u0026lt;\u0026lt;8|uint8(ConnState)) // mu guards hijackedv mu sync.Mutex // hijackedv is whether this connection has been hijacked // by a Handler with the Hijacker interface. // It is guarded by mu. hijackedv bool } HTTP 服务实现 具体的连接处理也是完整的HTTP 服务实现在conn结构体serve方法中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 // Serve a new connection. func (c *conn) serve(ctx context.Context) { c.remoteAddr = c.rwc.RemoteAddr().String() ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr()) defer func() { if err := recover(); err != nil \u0026amp;\u0026amp; err != ErrAbortHandler { const size = 64 \u0026lt;\u0026lt; 10 buf := make([]byte, size) buf = buf[:runtime.Stack(buf, false)] c.server.logf(\u0026#34;http: panic serving %v: %v\\n%s\u0026#34;, c.remoteAddr, err, buf) } if !c.hijacked() { c.close() c.setState(c.rwc, StateClosed) } }() if tlsConn, ok := c.rwc.(*tls.Conn); ok { if d := c.server.ReadTimeout; d != 0 { c.rwc.SetReadDeadline(time.Now().Add(d)) } if d := c.server.WriteTimeout; d != 0 { c.rwc.SetWriteDeadline(time.Now().Add(d)) } if err := tlsConn.Handshake(); err != nil { // If the handshake failed due to the client not speaking // TLS, assume they\u0026#39;re speaking plaintext HTTP and write a // 400 response on the TLS conn\u0026#39;s underlying net.Conn. if re, ok := err.(tls.RecordHeaderError); ok \u0026amp;\u0026amp; re.Conn != nil \u0026amp;\u0026amp; tlsRecordHeaderLooksLikeHTTP(re.RecordHeader) { io.WriteString(re.Conn, \u0026#34;HTTP/1.0 400 Bad Request\\r\\n\\r\\nClient sent an HTTP request to an HTTPS server.\\n\u0026#34;) re.Conn.Close() return } c.server.logf(\u0026#34;http: TLS handshake error from %s: %v\u0026#34;, c.rwc.RemoteAddr(), err) return } c.tlsState = new(tls.ConnectionState) *c.tlsState = tlsConn.ConnectionState() if proto := c.tlsState.NegotiatedProtocol; validNPN(proto) { if fn := c.server.TLSNextProto[proto]; fn != nil { h := initNPNRequest{ctx, tlsConn, serverHandler{c.server}} fn(c.server, tlsConn, h) } return } } // HTTP/1.x from here on. ctx, cancelCtx := context.WithCancel(ctx) c.cancelCtx = cancelCtx defer cancelCtx() c.r = \u0026amp;connReader{conn: c} c.bufr = newBufioReader(c.r) c.bufw = newBufioWriterSize(checkConnErrorWriter{c}, 4\u0026lt;\u0026lt;10) for { w, err := c.readRequest(ctx) if c.r.remain != c.server.initialReadLimitSize() { // If we read any bytes off the wire, we\u0026#39;re active. c.setState(c.rwc, StateActive) } if err != nil { const errorHeaders = \u0026#34;\\r\\nContent-Type: text/plain; charset=utf-8\\r\\nConnection: close\\r\\n\\r\\n\u0026#34; switch { case err == errTooLarge: // Their HTTP client may or may not be // able to read this if we\u0026#39;re // responding to them and hanging up // while they\u0026#39;re still writing their // request. Undefined behavior. const publicErr = \u0026#34;431 Request Header Fields Too Large\u0026#34; fmt.Fprintf(c.rwc, \u0026#34;HTTP/1.1 \u0026#34;+publicErr+errorHeaders+publicErr) c.closeWriteAndWait() return case isUnsupportedTEError(err): // Respond as per RFC 7230 Section 3.3.1 which says, // A server that receives a request message with a // transfer coding it does not understand SHOULD // respond with 501 (Unimplemented). code := StatusNotImplemented // We purposefully aren\u0026#39;t echoing back the transfer-encoding\u0026#39;s value, // so as to mitigate the risk of cross side scripting by an attacker. fmt.Fprintf(c.rwc, \u0026#34;HTTP/1.1 %d %s%sUnsupported transfer encoding\u0026#34;, code, StatusText(code), errorHeaders) return case isCommonNetReadError(err): return // don\u0026#39;t reply default: publicErr := \u0026#34;400 Bad Request\u0026#34; if v, ok := err.(badRequestError); ok { publicErr = publicErr + \u0026#34;: \u0026#34; + string(v) } fmt.Fprintf(c.rwc, \u0026#34;HTTP/1.1 \u0026#34;+publicErr+errorHeaders+publicErr) return } } // Expect 100 Continue support req := w.req if req.expectsContinue() { if req.ProtoAtLeast(1, 1) \u0026amp;\u0026amp; req.ContentLength != 0 { // Wrap the Body reader with one that replies on the connection req.Body = \u0026amp;expectContinueReader{readCloser: req.Body, resp: w} } } else if req.Header.get(\u0026#34;Expect\u0026#34;) != \u0026#34;\u0026#34; { w.sendExpectationFailed() return } c.curReq.Store(w) if requestBodyRemains(req.Body) { registerOnHitEOF(req.Body, w.conn.r.startBackgroundRead) } else { w.conn.r.startBackgroundRead() } // HTTP cannot have multiple simultaneous active requests.[*] // Until the server replies to this request, it can\u0026#39;t read another, // so we might as well run the handler in this goroutine. // [*] Not strictly true: HTTP pipelining. We could let them all process // in parallel even if their responses need to be serialized. // But we\u0026#39;re not going to implement HTTP pipelining because it // was never deployed in the wild and the answer is HTTP/2. serverHandler{c.server}.ServeHTTP(w, w.req) w.cancelCtx() if c.hijacked() { return } w.finishRequest() if !w.shouldReuseConnection() { if w.requestBodyLimitHit || w.closedRequestBodyEarly() { c.closeWriteAndWait() } return } c.setState(c.rwc, StateIdle) c.curReq.Store((*response)(nil)) if !w.conn.server.doKeepAlives() { // We\u0026#39;re in shutdown mode. We might\u0026#39;ve replied // to the user without \u0026#34;Connection: close\u0026#34; and // they might think they can send another // request, but such is life with HTTP/1.1. return } if d := c.server.idleTimeout(); d != 0 { c.rwc.SetReadDeadline(time.Now().Add(d)) if _, err := c.bufr.Peek(4); err != nil { return } } c.rwc.SetReadDeadline(time.Time{}) } } 创建 HTTP 客户端 1 2 3 4 5 6 7 func main() { r, err := http.Get(\u0026#34;http://www.baidu.com\u0026#34;) if err != nil { log.Fatalln(err) } fmt.Println(r) } 我们可以直接直接使用http.Get或http.Post发送请求\n","date":"2019-03-11T00:00:00Z","permalink":"https://cloudjjcc.github.io/p/net/http%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","title":"net/http源码分析"},{"content":"array 在 Go 语言中我们通过如下方式声明数组类型：\n1 2 [5]int [10]interface{} 数组类型包含数组长度以及元素类型，长度不同或者元素类型不同的数组是不同类型的\n1 2 3 4 5 6 7 8 9 var ( a [2]int b [3]int c [2]interface{} d [3]interface{} ) fmt.Printf(\u0026#34;a type:%T,b type:%T,c type:%T,d type:%T\\n\u0026#34;, a, b, c, d) // output // a type:[2]int,b type:[3]int,c type:[2]interface {},d type:[3]interface {} 数组长度可以根据字面量进行推导,可以通过下面的方式初始化数组，编译时会自动推导数组长度\n1 2 3 4 e := [...]int{1, 2, 3} fmt.Printf(\u0026#34;%T\\n\u0026#34;, e) // output // [3]int 可以通过内置函数len 获取数组长度\n1 2 3 4 f := [8]int{} fmt.Printf(\u0026#34;len:%d,cap:%d\\n\u0026#34;, len(f), cap(f)) // output // len:8,cap:8 slice 切片是变长数组的实现方案，切片类型如下：\n1 2 3 4 var ss []int fmt.Printf(\u0026#34;%T\\n\u0026#34;, ss) // output // []int 运行时结构为：\n1 2 3 4 5 type slice struct { array unsafe.Pointer //指向底层数组的指针 len int cap int } 可通过内置函数 len 获取长度，cap 获取容量,append进行元素追加\n初始化 直接使用 未初始化的切片等于nil,可以直接使用。因为切片实际上是一个结构体，声明一个切片时，所有字段初始化为零值\n1 2 3 4 5 6 7 var ss []int fmt.Printf(\u0026#34;%p,%p,%d,%d,%t\\n\u0026#34;, \u0026amp;ss, ss, len(ss), cap(ss), ss == nil) ss = append(ss, 1) fmt.Printf(\u0026#34;%p,%p,%d,%d\\n\u0026#34;, \u0026amp;ss, ss, len(ss), cap(ss)) // output // 0xc0001346d8,0x0,0,0,true // 0xc0001346d8,0xc00012a738,1,1 注意：当我们使用 %p 打印切片时，打印的实际上是底层数组的地址\n通过字面量初始化 1 s:=[]int{1,2,3} 通过 make 初始化切片 1 2 3 4 s6 := make([]int, 2, 6) fmt.Printf(\u0026#34;%p,%d,%d\\n\u0026#34;, s6, len(s6), cap(s6)) // output // 0xc00002c210,2,6 make 操作在编译时会根据切片大小、容量以及是否发生逃逸，来决定行为:\n当切片足够小且没有发生逃逸时会直接分配数组，然后对数组进行切片操作获得切片 1 2 var arr [4]int s := arr[:] 否则转化为对runtime.makeslice调用在堆上分配 下标操作 可以通过下标操作s[a:b:c]从已有数组或切片获取一个新的切片，新的切片共享底层数组,操作中 a 不指定默认为 0，b 不指定默认为 len(s),c 不指定默认为 cap(s),新生成的切片 len=b-a,cap=c-a\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 a := [5]int{} fmt.Printf(\u0026#34;addr:%p,len:%d,cap:%d\\n\u0026#34;, \u0026amp;a, len(a), cap(a)) s1 := a[:] fmt.Printf(\u0026#34;addr:%p,len:%d,cap:%d\\n\u0026#34;, s1, len(s1), cap(s1)) s2 := s1[1:] fmt.Printf(\u0026#34;addr:%p,len:%d,cap:%d\\n\u0026#34;, s2, len(s2), cap(s2)) s3 := s1[1:2] fmt.Printf(\u0026#34;addr:%p,len:%d,cap:%d\\n\u0026#34;, s3, len(s3), cap(s3)) s4 := s1[1:2:3] fmt.Printf(\u0026#34;addr:%p,len:%d,cap:%d\\n\u0026#34;, s4, len(s4), cap(s4)) // output //addr:0xc00002c240,len:5,cap:5 //addr:0xc00002c240,len:5,cap:5 //addr:0xc00002c248,len:4,cap:4 //addr:0xc00002c248,len:1,cap:4 //addr:0xc00002c248,len:1,cap:2 扩容 当通过append操作追加元素时，元素数量超过切片的容量时，切片会发生扩容。 扩容操作本质上是开辟一个新的容量足够大的数组，将原来的数组元素复制到新数组，将切片的数组指针指向新数组，新数组的容量选取需要考虑两方面的因素：\n扩容操作会涉及到内存拷贝，是一个比较耗时的操作，所以需要尽可能减少扩容发生的概率 尽量避免内存浪费，新分配的内存尽可能多的使用，原有的内存能够有效的回收 基于以上考虑，运行时根据切片的当期容量选择不同扩容策略：\n如果期望容量大于当前容量的两倍就会使用期望容量； 如果当前切片的长度小于 1024 就会将容量翻倍； 如果当前切片的长度大于 1024 就会每次增加 25% 的容量，直到新容量大于期望容量； string 运行时结构如下\n1 2 3 4 type stringStruct struct { str unsafe.Pointer //指向[]byte的指针 len int } 字符串的字面量形式 双引号 反引号 1 2 3 4 s:=\u0026#34;hello world\u0026#34; s1:=`a b ` 字符串类型转化 string 和 []byte 标准类型转换 1 2 3 a:=\u0026#34;hello world\u0026#34; b:=[]byte(a) c:=string(b) 实际上调用了runtime.stringtoslicebyte 和runtime.slicebytetostring函数 会进行内存拷贝\n可以通过指针类型转换来避免内存拷贝\n1 2 3 4 5 6 7 8 // string to slice no copy a:=\u0026#34;abcde\u0026#34; s := *(*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;a)) s.Cap=len(a) d:=*(*[]byte)(unsafe.Pointer(\u0026amp;s)) // slice to string no copy b := []byte(\u0026#34;abcde\u0026#34;) e := *(*string)(unsafe.Pointer(\u0026amp;b)) 注意：通过指针将一个string转为slice后应该避免修改，否则会报异常，因为string 字面量是只读的\n1 2 3 4 d[0] = \u0026#39;j\u0026#39; // ouput // unexpected fault address 0x15cfe93 // fatal error: fault string 和 []rune 标准类型转换 1 2 3 aa := \u0026#34;hello world\u0026#34; bb := []rune(aa) cc := string(bb) 底层会调用runtime.stringtoslicerune 和 runtime.slicerunetostring 函数\n字符串的拼接 通过+进行拼接 1 2 3 a:= \u0026#34;hello\u0026#34; b:=\u0026#34;world\u0026#34; c:=a+\u0026#34; \u0026#34;+b 编译器会转化为对runtime.concatstrings函数的调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // concatstrings implements a Go string concatenation x+y+z+... // The operands are passed in the slice a. // If buf != nil, the compiler has determined that the result does not // escape the calling function, so the string data can be stored in buf // if small enough. func concatstrings(buf *tmpBuf, a []string) string { idx := 0 l := 0 count := 0 for i, x := range a { n := len(x) if n == 0 { continue } if l+n \u0026lt; l { throw(\u0026#34;string concatenation too long\u0026#34;) } l += n count++ idx = i } if count == 0 { return \u0026#34;\u0026#34; } // If there is just one string and either it is not on the stack // or our result does not escape the calling frame (buf != nil), // then we can return that string directly. if count == 1 \u0026amp;\u0026amp; (buf != nil || !stringDataOnStack(a[idx])) { return a[idx] } s, b := rawstringtmp(buf, l) for _, x := range a { copy(b, x) b = b[len(x):] } return s } 该函数会计算出最终字符串的长度，一次分配内存空间给目标串，再把待拼接字符串依次拷贝到目标串\n通过strings.Builder 高效构建字符串 1 2 3 4 5 6 7 8 sb := strings.Builder{} sb.Grow(11) sb.WriteString(\u0026#34;hello\u0026#34;) sb.WriteByte(\u0026#39; \u0026#39;) sb.WriteString(\u0026#34;world\u0026#34;) fmt.Println(sb.String()) // output // hello world strings.Builder 用一个字节切片作为容器\n1 2 3 4 type Builder struct { addr *Builder // of receiver, to detect copies by value buf []byte } 通过提前预估容量，调用Grow函数，可以有效的减少内存分配次数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func (b *Builder) grow(n int) { buf := make([]byte, len(b.buf), 2*cap(b.buf)+n) copy(buf, b.buf) b.buf = buf } func (b *Builder) Grow(n int) { b.copyCheck() if n \u0026lt; 0 { panic(\u0026#34;strings.Builder.Grow: negative count\u0026#34;) } if cap(b.buf)-len(b.buf) \u0026lt; n { b.grow(n) } } String函数通过指针强制转换避免了从字节切片到字符串的内存拷贝\n1 2 3 4 // String returns the accumulated string. func (b *Builder) String() string { return *(*string)(unsafe.Pointer(\u0026amp;b.buf)) } map Go 语言中的 map 实现为 hash 表，运行时结构为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler\u0026#39;s definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields } 可用 len 获取 map 的长度\nmap 中实际存储键值对的容器是bucket(桶)，运行时结构为bmap,一个 bucket 可以存放 8 个键值对\n1 2 3 4 5 6 7 type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } map 的内存结构如下图：\n初始化 未初始化的 map 等于nil,对其进行写操作会报异常,我们申明的 map 类型变量实际上是 *hmap 类型的。\n1 2 3 4 5 6 7 8 9 10 var m1 map[string]int fmt.Printf(\u0026#34;%p,len:%d,size:%v,is nil:%t\\n\u0026#34;, m1, len(m1), unsafe.Sizeof(m1), m1 == nil) // output // 0x0,len:0,size:8,is nil:true fmt.Println(m1[\u0026#34;a\u0026#34;]) // output // 0 m1[\u0026#34;a\u0026#34;]=1 // output // panic: assignment to entry in nil map 字面量初始化 1 m:=map[int]string{1:\u0026#34;abc\u0026#34;,2:\u0026#34;cbe\u0026#34;} make初始化 可以指定初始容量\n1 2 m1:=make(map[int]string) m2:=make(map[int]string,2) 无论是字面量还是make函数，都会被 Go 语言编译器在类型检查期间转化为runtime.makemap 调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 func makemap(t *maptype, hint int, h *hmap) *hmap { mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } h.hash0 = fastrand() // Find the size parameter B which will hold the requested # of elements. // For hint \u0026lt; 0 overLoadFactor returns false since hint \u0026lt; bucketCnt. B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // allocate initial hash table // if B == 0, the buckets field is allocated lazily later (in mapassign) // If hint is large zeroing this memory could take a while. if h.B != 0 { var nextOverflow *bmap h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } 总结一下，初始化过程包括：\n创建 hmap 变量 初始化 hmap 中的字段（主要是 bucket 数组） 访问 直接访问,如果 key 不存在则返回元素零值 1 2 m:=map[int]string{1:\u0026#34;dog\u0026#34;,2:\u0026#34;cat\u0026#34;} fmt.Println(m[1]) comma_ok 形式，ok 字段表示 key 是否存在 1 2 m:=map[int]string{1:\u0026#34;dog\u0026#34;,2:\u0026#34;cat\u0026#34;} v,ok:=m[2] 这两种访问对应运行时函数runtime.mapaccess1 和runtime.mapaccess2 函数。\nkey的查找过程如下图：\n计算key的hash 根据hash的低B位在bucket数组中找到bucket 根据hash的高8位与bucket中的tophash数组进行比对，找到key的位置 遍历 可以通过 range 关键字遍历 map,注意遍历的顺序是随机的\n1 2 3 4 5 6 7 8 9 10 m2 := map[int]string{ 1: \u0026#34;cat\u0026#34;, 2: \u0026#34;dog\u0026#34;, } for k, v := range m2 { fmt.Println(k, v) } // output // 1 cat // 2 dog 编译器会重写for-range循环，将其换为对运行时函数runntime.mapiterinit和runtime.mapiternext的调用\n1 2 3 4 5 6 7 8 ha := a hit := hiter(n.Type) th := hit.Type mapiterinit(typename(t), ha, \u0026amp;hit) for ; hit.key != nil; mapiternext(\u0026amp;hit) { key := *hit.key val := *hit.val } 遍历的过程就是遍历每个bucket及其overflow bucket的过程，由于扩容的存在，会涉及到遍历新老bucket的问题。 遍历过程：\n创建一个迭代器并初始化（主要是确定初始bucket和初始cell） 不断地获取下一个bucket进行遍历，直到回到起始bucket 此过程的难点在于2 倍扩容时，老 bucket 会分裂到 2 个新 bucket 中去。而遍历操作，会按照新 bucket 的序号顺序进行，碰到老 bucket 未搬迁的情况时，要在老 bucket 中找到将来要搬迁到新 bucket 来的 key。\n写入 可以通过下标的方式进行写入\n1 2 3 m:=map[int]string{1:\u0026#34;abc\u0026#34;,2:\u0026#34;cbe\u0026#34;} m[1]=\u0026#34;ccc\u0026#34; m[3]=\u0026#34;ddd\u0026#34; 编译器会将其转换为对运行时函数runtime.mapassign的调用，写入分为更新和新增，无论哪种都得先查找 key 所在的位置，查找的过程同访问的过程，如果查找到 key,则对其 value 进行更新，否则新增 kv。新增 kv 会进行扩容检查，如果满足条件，会进行扩容。\n删除 可通过内置函数 delete 删除数组元素\n1 2 m:=map[int]string{1:\u0026#34;aaa\u0026#34;} delete(m,1) 运行时实际调用的函数为runtime.mapdelete\n删除的过程:\n判断flags标记，如果有写标记，则直接报异常\u0026quot;concurrent map writes\u0026quot; 根据key的hash找到bucket，如果map处于扩容中，则触发一次搬迁操作 找到key和value并清空，并设置对应tophash为emptyOne 将count减一 扩容 底层容器为数组，所以会涉及到扩容。扩容操作会涉及所有 bucket 的迁移，这是一个比较耗时的过程，所以扩容实现为渐进式扩容，当扩容开始后，每次对 map 的写操作会搬迁 1~2 个 bucket。\n当负载因子超过6.5时会发生翻倍扩容 当溢出桶的数量过多时会发生等量扩容 参考 Go 语言设计与实现 Go 程序员面试宝典 ","date":"2019-02-05T00:00:00Z","permalink":"https://cloudjjcc.github.io/p/go-%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","title":"go 常用数据结构"}]